{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Tokyo !\r\n",
      "Japanese food is delicious .\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"This is Tokyo !\" > tmp.txt\n",
    "!echo \"Japanese food is delicious .\" >> tmp.txt\n",
    "!cat tmp.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.dataset_readers.simple_language_modeling import SimpleLanguageModelingDatasetReader\n",
    "from allennlp.data.dataset_readers.multiprocess_dataset_reader import MultiprocessDatasetReader\n",
    "\n",
    "from allennlp.data.tokenizers.word_splitter import JustSpacesWordSplitter\n",
    "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
    "from allennlp.data.token_indexers.single_id_token_indexer import SingleIdTokenIndexer\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoTokenCharactersIndexer\n",
    "\n",
    "indexers = {\"tokens\": SingleIdTokenIndexer(),\n",
    "            \"token_characters\": ELMoTokenCharactersIndexer()}\n",
    "\n",
    "#indexers = {\"token_characters\": ELMoTokenCharactersIndexer()}\n",
    "reader = SimpleLanguageModelingDatasetReader(tokenizer=WordTokenizer(JustSpacesWordSplitter()), \n",
    "                                             token_indexers=indexers, \n",
    "                                             max_sequence_length=400, \n",
    "                                             start_tokens=[\"<S>\"], \n",
    "                                             end_tokens=[\"</S>\"])\n",
    "\n",
    "NUM_THREADS = 2\n",
    "reader = MultiprocessDatasetReader(base_reader=reader, num_workers=NUM_THREADS, output_queue_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = reader.read(\"tmp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO/MainProcess] starting worker 0\n",
      "[INFO/MainProcess] starting worker 1\n",
      "[INFO/Process-2] child process calling self.run()\n",
      "[INFO/Process-3] child process calling self.run()\n",
      "[INFO/Process-2] reading instances from tmp.txt\n",
      "[INFO/MainProcess] worker 1 finished (1/2)\n",
      "[INFO/Process-3] process shutting down\n",
      "[INFO/Process-2] process shutting down\n",
      "[INFO/MainProcess] worker 0 finished (2/2)\n",
      "[INFO/Process-3] process exiting with exitcode 0\n",
      "[INFO/Process-2] process exiting with exitcode 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance with fields:\n",
      " \t source: TextField of length 6 with text: \n",
      " \t\t[<S>, This, is, Tokyo, !, </S>]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer', 'token_characters': 'ELMoTokenCharactersIndexer'} \n",
      "\n",
      "Instance with fields:\n",
      " \t source: TextField of length 7 with text: \n",
      " \t\t[<S>, Japanese, food, is, delicious, ., </S>]\n",
      " \t\tand TokenIndexers : {'tokens': 'SingleIdTokenIndexer', 'token_characters': 'ELMoTokenCharactersIndexer'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> vocabs/non_padded_namespaces.txt <==\r\n",
      "*labels\r\n",
      "*tags\r\n",
      "\r\n",
      "==> vocabs/tokens.txt <==\r\n",
      "</S>\r\n",
      "<S>\r\n",
      "@@UNKNOWN@@\r\n",
      "the\r\n",
      ",\r\n",
      ".\r\n",
      "to\r\n",
      "of\r\n",
      "and\r\n",
      "a\r\n"
     ]
    }
   ],
   "source": [
    "!head vocabs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  793471 vocabs/tokens.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l vocabs/tokens.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp non_padded_namespaces.txt vocabs/\n",
    "# !cp tokens.txt vocabs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.common import Params\n",
    "\n",
    "vocab = Vocabulary.from_params(Params(params={\"directory_path\": \"./vocabs\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocabulary with namespaces:  tokens, Size: 793472 || Non Padded Namespaces: {'*labels', '*tags'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models.language_model import LanguageModel\n",
    "from allennlp.modules.seq2seq_encoders.bidirectional_language_model_transformer import BidirectionalLanguageModelTransformer\n",
    "from allennlp.modules.text_field_embedders.basic_text_field_embedder import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders.token_characters_encoder import TokenCharactersEncoder\n",
    "from allennlp.modules.token_embedders.embedding import Embedding\n",
    "from allennlp.modules.seq2vec_encoders.cnn_highway_encoder import CnnHighwayEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(num_embeddings=262, embedding_dim=16)\n",
    "filters = [\n",
    "    [1, 32],\n",
    "    [2, 32],\n",
    "    [3, 64],\n",
    "    [4, 128],\n",
    "    [5, 256]]\n",
    "\n",
    "encoder = CnnHighwayEncoder(activation=\"relu\",\n",
    "                            embedding_dim=16, \n",
    "                            filters=filters, \n",
    "                            num_highway=1, \n",
    "                            projection_dim=256, \n",
    "                            projection_location=\"after_highway\", \n",
    "                            do_layer_norm=True)\n",
    "\n",
    "character_embedder = TokenCharactersEncoder(embedding=embedding, encoder=encoder)\n",
    "token_embedders = {\"token_characters\": character_embedder}\n",
    "text_field_embedder = BasicTextFieldEmbedder(allow_unmatched_keys=True, token_embedders=token_embedders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15, 512])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(filters).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualizer = BidirectionalLanguageModelTransformer(input_dim=256, \n",
    "                                                       hidden_dim=512, \n",
    "                                                       num_layers=2, \n",
    "                                                       dropout=0.1, \n",
    "                                                       input_dropout=0.1)\n",
    "\n",
    "model = LanguageModel(vocab=vocab, \n",
    "                      text_field_embedder=text_field_embedder, \n",
    "                      contextualizer=contextualizer, \n",
    "                      bidirectional=True, \n",
    "                      num_samples=8192, \n",
    "                      sparse_embeddings=True, \n",
    "                      dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206,726,880\n",
      "206,726,880\n",
      "LanguageModel(\n",
      "  (_text_field_embedder): BasicTextFieldEmbedder(\n",
      "    (token_embedder_token_characters): TokenCharactersEncoder(\n",
      "      (_embedding): TimeDistributed(\n",
      "        (_module): Embedding()\n",
      "      )\n",
      "      (_encoder): TimeDistributed(\n",
      "        (_module): CnnHighwayEncoder(\n",
      "          (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
      "          (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
      "          (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
      "          (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
      "          (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
      "          (_highways): Highway(\n",
      "            (_layers): ModuleList(\n",
      "              (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (_projection): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (_layer_norm): LayerNorm()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_contextualizer): BidirectionalLanguageModelTransformer(\n",
      "    (_forward_transformer): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linears): ModuleList(\n",
      "              (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=256, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (sublayer): ModuleList(\n",
      "            (0): SublayerConnection(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (1): SublayerConnection(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linears): ModuleList(\n",
      "              (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=256, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (sublayer): ModuleList(\n",
      "            (0): SublayerConnection(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (1): SublayerConnection(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm()\n",
      "    )\n",
      "    (_backward_transformer): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linears): ModuleList(\n",
      "              (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=256, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (sublayer): ModuleList(\n",
      "            (0): SublayerConnection(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (1): SublayerConnection(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderLayer(\n",
      "          (self_attn): MultiHeadedAttention(\n",
      "            (linears): ModuleList(\n",
      "              (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=256, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=256, bias=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "          (sublayer): ModuleList(\n",
      "            (0): SublayerConnection(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (1): SublayerConnection(\n",
      "              (norm): LayerNorm()\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm()\n",
      "    )\n",
      "    (_position): PositionalEncoding()\n",
      "    (_dropout): Dropout(p=0.1)\n",
      "  )\n",
      "  (_softmax_loss): SampledSoftmaxLoss(\n",
      "    (softmax_w): Embedding(793472, 256, sparse=True)\n",
      "    (softmax_b): Embedding(793472, 1, sparse=True)\n",
      "  )\n",
      "  (_dropout): Dropout(p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def get_params(model, requires_grad=None):\n",
    "    return [p for p in model.parameters()\n",
    "            if requires_grad is None or p.requires_grad == requires_grad]\n",
    "\n",
    "\n",
    "def count_parameters(model, requires_grad=None):\n",
    "    return sum(p.numel() for p in get_params(model, requires_grad))\n",
    "\n",
    "print(f\"{count_parameters(model, requires_grad=True):,}\")\n",
    "print(f\"{count_parameters(model, requires_grad=None):,}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators.bucket_iterator import BucketIterator\n",
    "from allennlp.data.iterators.multiprocess_iterator import MultiprocessIterator\n",
    "\n",
    "bucket_iterator = BucketIterator(sorting_keys=[[\"source\", \"num_tokens\"]], \n",
    "                                 batch_size=512, \n",
    "                                 maximum_samples_per_batch=[\"num_tokens\", 2000])\n",
    "\n",
    "bucket_iterator = MultiprocessIterator(base_iterator=bucket_iterator, num_workers=NUM_THREADS, output_queue_size=500)\n",
    "bucket_iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disable GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s][INFO/SyncManager-44] child process calling self.run()\n",
      "[INFO/SyncManager-44] created temp directory /var/folders/_r/l1tzvmmj3ys67045yy0fy3r9b2c7bz/T/pymp-t_xp6475\n",
      "[INFO/SyncManager-44] manager serving at '/var/folders/_r/l1tzvmmj3ys67045yy0fy3r9b2c7bz/T/pymp-t_xp6475/listener-iy1wtc10'\n",
      "[INFO/Process-45] child process calling self.run()\n",
      "[INFO/Process-45] starting worker 0\n",
      "[INFO/Process-46] child process calling self.run()\n",
      "[INFO/Process-47] child process calling self.run()\n",
      "[INFO/Process-45] starting worker 1\n",
      "[INFO/Process-45:1] child process calling self.run()\n",
      "[INFO/Process-45:1] reading instances from tmp.txt\n",
      "[INFO/Process-45:2] child process calling self.run()\n",
      "[INFO/Process-45:2] process shutting down\n",
      "[INFO/Process-45:1] process shutting down\n",
      "[INFO/Process-45] worker 1 finished (1/2)\n",
      "[INFO/Process-45] worker 0 finished (2/2)\n",
      "[INFO/Process-45:1] process exiting with exitcode 0\n",
      "[INFO/Process-45:2] process exiting with exitcode 0\n",
      "[INFO/Process-45] process shutting down\n",
      "[INFO/Process-47] process shutting down\n",
      "[INFO/Process-46] process shutting down\n",
      "[INFO/Process-45] process exiting with exitcode 0\n",
      "[INFO/Process-47] process exiting with exitcode 0\n",
      "[INFO/Process-46] process exiting with exitcode 0\n",
      "loss: 14.0283 ||: 100%|██████████| 1/1 [00:03<00:00,  3.93s/it][INFO/MainProcess] worker 1 finished (1 / 2)\n",
      "loss: 13.8367 ||: : 2it [00:04,  3.03s/it]                     [INFO/MainProcess] worker 0 finished (2 / 2)\n",
      "[INFO/MainProcess] sending shutdown message to manager\n",
      "[INFO/SyncManager-44] process shutting down\n",
      "[INFO/SyncManager-44] process exiting with exitcode 0\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s][INFO/SyncManager-48] child process calling self.run()\n",
      "[INFO/SyncManager-48] created temp directory /var/folders/_r/l1tzvmmj3ys67045yy0fy3r9b2c7bz/T/pymp-ro8dxo3t\n",
      "[INFO/SyncManager-48] manager serving at '/var/folders/_r/l1tzvmmj3ys67045yy0fy3r9b2c7bz/T/pymp-ro8dxo3t/listener-n__1aen1'\n",
      "[INFO/Process-49] child process calling self.run()\n",
      "[INFO/Process-50] child process calling self.run()\n",
      "[INFO/Process-49] starting worker 0\n",
      "[INFO/Process-51] child process calling self.run()\n",
      "[INFO/Process-49] starting worker 1\n",
      "[INFO/Process-49:1] child process calling self.run()\n",
      "[INFO/Process-49:1] reading instances from tmp.txt\n",
      "[INFO/Process-49:2] child process calling self.run()\n",
      "[INFO/Process-49:1] process shutting down\n",
      "[INFO/Process-49:2] process shutting down\n",
      "[INFO/Process-49] worker 1 finished (1/2)\n",
      "[INFO/Process-49:2] process exiting with exitcode 0\n",
      "[INFO/Process-49] worker 0 finished (2/2)\n",
      "[INFO/Process-49:1] process exiting with exitcode 0\n",
      "[INFO/Process-49] process shutting down\n",
      "[INFO/Process-50] process shutting down\n",
      "[INFO/Process-51] process shutting down\n",
      "[INFO/Process-49] process exiting with exitcode 0\n",
      "[INFO/Process-50] process exiting with exitcode 0\n",
      "[INFO/Process-51] process exiting with exitcode 0\n",
      "loss: 13.6936 ||: : 2it [00:03,  1.80s/it]                     [INFO/MainProcess] worker 0 finished (1 / 2)\n",
      "[INFO/MainProcess] worker 1 finished (2 / 2)\n",
      "[INFO/MainProcess] sending shutdown message to manager\n",
      "[INFO/SyncManager-48] process shutting down\n",
      "[INFO/SyncManager-48] process exiting with exitcode 0\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s][INFO/SyncManager-52] child process calling self.run()\n",
      "[INFO/SyncManager-52] created temp directory /var/folders/_r/l1tzvmmj3ys67045yy0fy3r9b2c7bz/T/pymp-6kl1xgaf\n",
      "[INFO/SyncManager-52] manager serving at '/var/folders/_r/l1tzvmmj3ys67045yy0fy3r9b2c7bz/T/pymp-6kl1xgaf/listener-kgn109dm'\n",
      "[INFO/Process-53] child process calling self.run()\n",
      "[INFO/Process-54] child process calling self.run()\n",
      "[INFO/Process-53] starting worker 0\n",
      "[INFO/Process-55] child process calling self.run()\n",
      "[INFO/Process-53] starting worker 1\n",
      "[INFO/Process-53:1] child process calling self.run()\n",
      "[INFO/Process-53:1] reading instances from tmp.txt\n",
      "[INFO/Process-53:2] child process calling self.run()\n",
      "[INFO/Process-53:1] process shutting down\n",
      "[INFO/Process-53:2] process shutting down\n",
      "[INFO/Process-53] worker 0 finished (1/2)\n",
      "[INFO/Process-53] worker 1 finished (2/2)\n",
      "[INFO/Process-53:1] process exiting with exitcode 0\n",
      "[INFO/Process-53:2] process exiting with exitcode 0\n",
      "[INFO/Process-53] process shutting down\n",
      "[INFO/Process-55] process shutting down\n",
      "[INFO/Process-54] process shutting down\n",
      "[INFO/Process-53] process exiting with exitcode 0\n",
      "[INFO/Process-55] process exiting with exitcode 0\n",
      "[INFO/Process-54] process exiting with exitcode 0\n",
      "loss: 13.4646 ||: : 2it [00:02,  1.58s/it]                     [INFO/MainProcess] worker 1 finished (1 / 2)\n",
      "[INFO/MainProcess] worker 0 finished (2 / 2)\n",
      "[INFO/MainProcess] sending shutdown message to manager\n",
      "[INFO/SyncManager-52] process shutting down\n",
      "[INFO/SyncManager-52] process exiting with exitcode 0\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s][INFO/SyncManager-56] child process calling self.run()\n",
      "[INFO/SyncManager-56] created temp directory /var/folders/_r/l1tzvmmj3ys67045yy0fy3r9b2c7bz/T/pymp-znuwv2xl\n",
      "[INFO/SyncManager-56] manager serving at '/var/folders/_r/l1tzvmmj3ys67045yy0fy3r9b2c7bz/T/pymp-znuwv2xl/listener-6_pvluo2'\n",
      "[INFO/Process-57] child process calling self.run()\n",
      "[INFO/Process-57] starting worker 0\n",
      "[INFO/Process-58] child process calling self.run()\n",
      "[INFO/Process-57] starting worker 1\n",
      "[INFO/Process-57:1] child process calling self.run()\n",
      "[INFO/Process-59] child process calling self.run()\n",
      "[INFO/Process-57:1] reading instances from tmp.txt\n",
      "[INFO/Process-57:2] child process calling self.run()\n",
      "[INFO/Process-57:1] process shutting down\n",
      "[INFO/Process-57:2] process shutting down\n",
      "[INFO/Process-57] worker 0 finished (1/2)\n",
      "[INFO/Process-57] worker 1 finished (2/2)\n",
      "[INFO/Process-57:1] process exiting with exitcode 0\n",
      "[INFO/Process-57:2] process exiting with exitcode 0\n",
      "[INFO/Process-57] process shutting down\n",
      "[INFO/Process-58] process shutting down\n",
      "[INFO/Process-59] process shutting down\n",
      "[INFO/Process-57] process exiting with exitcode 0\n",
      "[INFO/Process-58] process exiting with exitcode 0\n",
      "[INFO/Process-59] process exiting with exitcode 0\n",
      "loss: 13.4794 ||: 100%|██████████| 1/1 [00:01<00:00,  1.86s/it][INFO/MainProcess] worker 0 finished (1 / 2)\n",
      "loss: 13.5775 ||: : 2it [00:02,  1.60s/it]                     [INFO/MainProcess] worker 1 finished (2 / 2)\n",
      "[INFO/MainProcess] sending shutdown message to manager\n",
      "[INFO/SyncManager-56] process shutting down\n",
      "[INFO/SyncManager-56] Failure to send message: ('#RETURN', None)\n",
      "[INFO/SyncManager-56] process exiting with exitcode 0\n",
      "\n",
      "unable to check gpu_memory_mb(), continuing\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/common/util.py\", line 379, in gpu_memory_mb\n",
      "    encoding='utf-8')\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/subprocess.py\", line 356, in check_output\n",
      "    **kwargs).stdout\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/subprocess.py\", line 423, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/subprocess.py\", line 729, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/subprocess.py\", line 1318, in _execute_child\n",
      "    part = os.read(errpipe_read, 50000)\n",
      "KeyboardInterrupt\n",
      "  0%|          | 0/1 [00:00<?, ?it/s][INFO/SyncManager-60] incref failed: [Errno 2] No such file or directory\n",
      "[INFO/SyncManager-60] child process calling self.run()\n",
      "[INFO/SyncManager-60] created temp directory /var/folders/_r/l1tzvmmj3ys67045yy0fy3r9b2c7bz/T/pymp-h6vz1ncg\n",
      "[INFO/SyncManager-60] manager serving at '/var/folders/_r/l1tzvmmj3ys67045yy0fy3r9b2c7bz/T/pymp-h6vz1ncg/listener-wm8e34d2'\n",
      "[INFO/Process-61] incref failed: [Errno 2] No such file or directory\n",
      "[INFO/Process-62] incref failed: [Errno 2] No such file or directory\n",
      "[INFO/Process-61] child process calling self.run()\n",
      "[INFO/Process-62] child process calling self.run()\n",
      "[INFO/Process-61] process shutting down\n",
      "[INFO/Process-63] incref failed: [Errno 2] No such file or directory\n",
      "Process Process-61:\n",
      "[INFO/Process-63] child process calling self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/multiprocess_iterator.py\", line 47, in _queuer\n",
      "    for instance in instances:\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/dataset_readers/multiprocess_dataset_reader.py\", line 133, in _instances\n",
      "    input_queue = manager.Queue(num_shards * self.epochs_per_read + self.num_workers)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/managers.py\", line 662, in temp\n",
      "    token, exp = self._create(typeid, *args, **kwds)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/managers.py\", line 554, in _create\n",
      "    conn = self._Client(self._address, authkey=self._authkey)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "[INFO/Process-61] process exiting with exitcode 1\n",
      "[INFO/Process-62] process shutting down\n",
      "[INFO/Process-63] process shutting down\n",
      "[INFO/SyncManager-60] process shutting down\n",
      "[INFO/SyncManager-60] process exiting with exitcode 0\n",
      "Process Process-63:\n",
      "Process Process-62:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/multiprocess_iterator.py\", line 31, in _create_tensor_dicts\n",
      "    for tensor_dict in iterator(instances(), num_epochs=1, shuffle=shuffle):\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/data_iterator.py\", line 144, in __call__\n",
      "    for batch in batches:\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/multiprocess_iterator.py\", line 31, in _create_tensor_dicts\n",
      "    for tensor_dict in iterator(instances(), num_epochs=1, shuffle=shuffle):\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/bucket_iterator.py\", line 112, in _create_batches\n",
      "    for instance_list in self._memory_sized_lists(instances):\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/data_iterator.py\", line 216, in _memory_sized_lists\n",
      "    yield from lazy_groups_of(iterator, self._batch_size)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/data_iterator.py\", line 144, in __call__\n",
      "    for batch in batches:\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/common/util.py\", line 105, in <lambda>\n",
      "    return iter(lambda: list(islice(iterator, 0, group_size)), [])\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/bucket_iterator.py\", line 112, in _create_batches\n",
      "    for instance_list in self._memory_sized_lists(instances):\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/data_iterator.py\", line 216, in _memory_sized_lists\n",
      "    yield from lazy_groups_of(iterator, self._batch_size)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/data_iterator.py\", line 175, in _take_instances\n",
      "    yield from iter(instances)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/common/util.py\", line 105, in <lambda>\n",
      "    return iter(lambda: list(islice(iterator, 0, group_size)), [])\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/multiprocess_iterator.py\", line 26, in instances\n",
      "    instance = input_queue.get()\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/data_iterator.py\", line 175, in _take_instances\n",
      "    yield from iter(instances)\n",
      "  File \"<string>\", line 2, in get\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/multiprocess_iterator.py\", line 26, in instances\n",
      "    instance = input_queue.get()\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"<string>\", line 2, in get\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "[INFO/Process-63] process exiting with exitcode 1\n",
      "  File \"/Users/phiradet.bangcharoe/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "[INFO/Process-62] process exiting with exitcode 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2b7b14ac6390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                   \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                   cuda_device=cuda_device)\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/allennlp/training/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;31m# get peak of memory usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/allennlp/training/trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    313\u001b[0m                                          total=num_training_batches)\n\u001b[1;32m    314\u001b[0m         \u001b[0mcumulative_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_generator_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mbatches_this_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_num_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/allennlp/common/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mspecified\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msmaller\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0minstances\u001b[0m \u001b[0mleft\u001b[0m \u001b[0mover\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m def pad_sequence_to_length(sequence: List,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/allennlp/data/iterators/multiprocess_iterator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, instances, num_epochs, shuffle)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mnum_finished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mnum_finished\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mnum_finished\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'#RETURN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.training.optimizers import DenseSparseAdam\n",
    "from allennlp.training.learning_rate_schedulers.noam import NoamLR\n",
    "\n",
    "optimizer = DenseSparseAdam(model.parameters())\n",
    "scheduler = NoamLR(optimizer, model_size=512, warmup_steps=6000)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Enable GPU\")\n",
    "    cuda_device = 0\n",
    "    model = model.cuda(cuda_device)\n",
    "else:\n",
    "    print(\"Disable GPU\")\n",
    "    cuda_device = -1\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=bucket_iterator,\n",
    "                  train_dataset=dataset,\n",
    "                  learning_rate_scheduler=scheduler,\n",
    "                  num_epochs=10,\n",
    "                  cuda_device=cuda_device)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'431,434,432'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
